{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos.\n",
    "\n",
    "Problemas comunes al leer datos.\n",
    "\n",
    "## Leer el archivo. \n",
    "\n",
    "Las formas mas comunes de archivos son:\n",
    "- csv\n",
    "- Tab separated values\n",
    "- xlsx \n",
    "- zip\n",
    "- .txt\n",
    "- json\n",
    "- html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es importar las librerías que nos ayudarán en todo el proceso de limpieza de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de cada uno de los tipos de dato, tiene diferentes maneras de mandarlo a llamar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Csv:\n",
    "df = pd.read_csv(\"file.csv\")\n",
    "\n",
    "Text:\n",
    "df_tab = pd.read_table(\"file.txt\")\n",
    "\n",
    "Excel:\n",
    "df_excel = pd.read_excel(\"examplefileexcel.xlsx\")\n",
    "\n",
    "ZIP:\n",
    "import zipfile as zp\n",
    "archive = zp.ZipFile(\"examplefile.zip\",\"r\")\n",
    "df_zip = archive.read(\"examplefile.csv\")\n",
    "\n",
    "Read a text\n",
    "txt_file = open(\"examplefile.txt\",\"r\")\n",
    "txt_file.read()\n",
    "\n",
    "Json:\n",
    "df_json = pd.read_json(\"myvalidjsonfile.json\")\n",
    "\n",
    "Html:\n",
    "url = 'http://www.fdic.gov/bank/individual/failed/banklist.html'\n",
    "df_html = pd.read_html(url)\n",
    "df_html_table = pd.read_html(\"examplehtml.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la mayoría de los casos cuando se trabaja con Excel, o si el archivo contiene simbolos que la computadora no reconoce (acentos, letras que pertenecen a otro lenguaje que no sea el inglés estandar) nos marcará un error de ejecución. Para esto se utiliza el encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"unclean_data1.csv\",encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El utf8 se utiliza generalmente para simbolos extraños."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los datos.\n",
    "\n",
    "Una vez que ya tenemos cargada nuestra base de datos al notebook, podemos empezar a manipularla. Para poder fijar el objetivo de nuestra limpieza, primero tenemos que revisar cuales son los datos que conforman la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta instrucción de shape nos enteramos de cuantas columnas y cuantas filas cuenta nuestra base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el comando de head podemos ver los primeros cinco elementos de cada una de las columnas. En caso de que se quieran ver más datos que el default de 5, dentro del parentesis se anota el numero de elementos que queremos mostrar. Esto es especialmente importante para datos csv o json, ya que al no tener el formato natural de un xlsx en tabla, cuando mandamos a llamar la base de datos, nos aparecen todos los datos separados por comas, o parentesis, lo que no lo hace visualmente sencillo de entender y sacar conclusiones.\n",
    "\n",
    "\n",
    "El contrario de head es tail, y nos muestra los últimos valores del dataset, y de igual manera, por default nos muestra 5, pero podemos especificarle cuantos datos queremos ver en realidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra manera de ver los datos es por medio del comando de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso los nombres de las columnas apareceran en una lista, tal y como aparecen en la base de datos. Aqui debemos tener en cuenta que python no es muy amigable con titulos con espacios o palabras con caracteres extraños, por lo que utilizando esta misma instrucción, podemos cambiar el nombre de la columna a uno que nos facilite la extracción de su información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'Nombre de la columna':'Nuevo_nombre'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se quiere saber el tipo de dato que contiene cada columna, usamos el comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y si queremos saber el tipo de datos que contiene una columna en especifico, cambiamos la instrucción a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['Nombre_columna'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que en una columna existan varios tipos de elementos numericos, puedes normalizarlo con la siguiente instrucción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.Nombre_columna.astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En donde todos los valores dentor de la columna Nombre_columna se convertiran a flotantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Nota:\n",
    "Se tiene que tener cuidado con este comando, ya que si se requiere cambiar de flotante a enteros, y lo que queremos es una predicción segura, podemos estar perdiendo datos importantes al momento de convertirlos. Lo que nos lleva al problema de datos nulos que veremos mas adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saber el nombre de las columnas tambien nos ayuda para localizar elementos dentro de ellas. Con el comando unique podemos extraer los valores unicos de la columna. En caso de que nosotros queramos hacer un clasificador, con esta instrucción podemos darnos cuenta de las etiquetas de salida que tiene cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.Nombre_columna.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que sabemos los valores de nuestra columna Nombre_columna, podemos hacer agrupaciones de datos. Por ejemplo, si en la columna Nombre_columna tengo como datos unicos lo siguiente:\n",
    "\n",
    "- Clase_1\n",
    "- Clase_2\n",
    "- Clase_3\n",
    "\n",
    "Yo puedo agrupar todos los valores dentro de la clase en la que estan etiquetados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_1 = data_frame[data_frame['Nombre_columna']=='Clase_1']\n",
    "\n",
    "clase_1.to_csv('Solo_clase1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se quiere encontrar un valor dentro de un data frame, dependiendo de los valores de otra columna se utiliza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_1_vs_fecha = data_frame.loc[data_frame.Nombre_columna == 'Clase_1'].Fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo de arriba, en la variable de clase_1_vs_fecha se van a guardar los valores de la columna Fecha que coincidan con los valores de 'Clase_1' en la columna de Nombre_columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponiendo ahora que solo tengo dos tipos de clase en la columna Nombre_columna, y quiero cambiar los nombres dentro de los datos unicos para poder realizar una clasificacion binaria, puedo hacer lo siguente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.Nombre_columna.replace(to_replace = dict(Clase_1 = 1, Clase_2 = 0), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que quiera deshacerme de una columna que no necesito, como por ejemplo, si mi base de datos cuenta con el nombre del cliente en la columna Nombre, dentro del data_frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.drop('Nombre',axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREGUNTAS DE INTERES:\n",
    "\n",
    "- ¿Para que me puede servir estas agrupaciones para la práctica siguiente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos nulos.\n",
    "\n",
    "Para estos casos, primero se tiene que hacer un análisis de los valores faltantes. Para esto utilizamos los siguientes comandos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que nos da como resultado la base de datos, pero en cada celda esta un valor boleano de True o False para indicarnos cuales son los valores nulos (True). Esto puede servirnos para visualizar una base de datos pequeña, pero en caso de tener muchos datos, es necesario dar un resumen del comportamiento de los datos nulos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al agregar el any a la sentencia, nos va a dar como resultado la lista de los nombres de las columnas, y a un lado los valores boleanos de True o False, para decirnos si en esa columna hay valores nulos (True) o no los hay (False).\n",
    "\n",
    "Esto nos da una idea de donde debemos buscar para resolver nuestros valores nulos. Para tener una idea más acertada de cuantos valores nulos tenemos por columna, podemos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que nos dará como salida la suma de los valores nulos que existen en cada columna.\n",
    "\n",
    "Ahora, para poder rellenar los valores nulos, es importante hacer una nueva variable que pueda contener tu dataframe, en caso de que te equivoques al modificar datos. Tambien puede ser una opcion buena el hacer una copia de tus datos en caso de que quieras volver a manejarlos desde cero.\n",
    "\n",
    "### Preguntas de interes:\n",
    "- Importancia del analisis previo de los datos antes de iniciar las modificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_0 = data_frame.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esa instrucción, todos los valores que tengan celdas nulas, se llenaran con ceros. Esto también es una desisión que se tiene que deliberar, ya que si tus datos si reportan valores de cero, puedes afectar el resultado de tus pruebas estadisticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el comando de arriba lo que le estas indicando es que quieres que te elimine todas las filas que contengan datos nulos. En la parte de abajo tenemos que quieres eliminar todas las columnas que tengan datos nulos dentro de tu base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_column = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea:\n",
    "\n",
    "Dada una base de datos en grupo, realizar las diferentes técnicas de pre procesamiento de datos. Pueden ser las mencionadas en esta práctica, o pueden agregar nuevas. Los temas que tienen que tocar de manera obligatoria:\n",
    "\n",
    "- Importar librerias y base de datos.\n",
    "- Visualizar los datos.\n",
    "- Descrpcion básica de columnas (tipo, elementos, celdas vacias, etc.)\n",
    "- El objetivo es una clasificación con los datos, asi que hay que acomodar los datos de manera que se nos facilite esta tarea.\n",
    "- Cambiar nombres de columnas.\n",
    "- Guardar otros archivos con agrupaciones.\n",
    "- Responder las preguntas de interes.\n",
    "\n",
    "Tareas extras:\n",
    "(Puntos extras)\n",
    "- Investigar los siguientes comandos:\n",
    "?df.dropna()\n",
    "?df.astype\n",
    "\n",
    "- Realizar una tarea de preprocesamiento no mencionada en esta práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace('\\*','',regex=True).astype(float)\n",
    "\n",
    "df.dropna(thresh=int(df.shape[0] * .9), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
